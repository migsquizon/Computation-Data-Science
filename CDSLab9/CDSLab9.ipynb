{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 train sequences\n",
      "32000 test sequences\n",
      "Found 400000 word vectors.\n",
      "Train on 102400 samples, validate on 25600 samples\n",
      "Epoch 1/3\n",
      "102400/102400 [==============================] - 38s 368us/step - loss: 0.6964 - accuracy: 0.5035 - val_loss: 0.6937 - val_accuracy: 0.5009\n",
      "Epoch 2/3\n",
      "102400/102400 [==============================] - 39s 384us/step - loss: 0.6970 - accuracy: 0.4966 - val_loss: 0.6956 - val_accuracy: 0.5024\n",
      "Epoch 3/3\n",
      "102400/102400 [==============================] - 41s 398us/step - loss: 0.6966 - accuracy: 0.5012 - val_loss: 0.6978 - val_accuracy: 0.4996\n",
      "32000/32000 [==============================] - 5s 144us/step\n",
      "Test score: 0.6976341347694397\n",
      "Test accuracy: 0.5051875114440918\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters, imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, Dense, Dropout, Activation, Embedding, TimeDistributed, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "# load in training/test set\n",
    "data = pd.read_csv('tweets.160k.random.csv', encoding='utf-8')\n",
    "data.head()\n",
    "\n",
    "data['label'].value_counts()\n",
    "\n",
    "vocab_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocab_size)\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['text'])\n",
    "word_index = tokenizer.word_index\n",
    "tweets = sequence.pad_sequences(sequences, padding='post', maxlen=50)\n",
    "\n",
    "\n",
    "labels = data['label']\n",
    "labels = labels.replace(4,1) # replace label '4' with '1' to facilitate one-hot encoding\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train) # 2 classes\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "embeddings_index = {}\n",
    "# GLOVE_DIR = \"/Users/soujanyaporia/Downloads/\"\n",
    "f = open(os.path.join('glove.6B.50d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=3, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102400 samples, validate on 25600 samples\n",
      "Epoch 1/3\n",
      "102400/102400 [==============================] - 148s 1ms/step - loss: 0.5950 - accuracy: 0.6780 - categorical_accuracy: 0.6780 - val_loss: 0.5457 - val_accuracy: 0.7215 - val_categorical_accuracy: 0.7215\n",
      "Epoch 2/3\n",
      "102400/102400 [==============================] - 155s 2ms/step - loss: 0.5365 - accuracy: 0.7300 - categorical_accuracy: 0.7300 - val_loss: 0.5152 - val_accuracy: 0.7454 - val_categorical_accuracy: 0.7454\n",
      "Epoch 3/3\n",
      "102400/102400 [==============================] - 150s 1ms/step - loss: 0.5098 - accuracy: 0.7492 - categorical_accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7502 - val_categorical_accuracy: 0.7502\n",
      "32000/32000 [==============================] - 14s 429us/step\n",
      "Test score: 0.5134314106702804\n",
      "Test accuracy: 0.7484999895095825\n"
     ]
    }
   ],
   "source": [
    "# hidden_size = len(word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,EMBEDDING_DIM, weights=[embedding_matrix], trainable=False))\n",
    "model.add(LSTM(128))\n",
    "# model.add(LSTM(128))\n",
    "model.add(Dropout(0.1))\n",
    "model.add((Dense(2)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=3, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102400 samples, validate on 25600 samples\n",
      "Epoch 1/3\n",
      "102400/102400 [==============================] - 140s 1ms/step - loss: 0.5897 - accuracy: 0.6850 - categorical_accuracy: 0.6850 - val_loss: 0.5668 - val_accuracy: 0.7102 - val_categorical_accuracy: 0.7102\n",
      "Epoch 2/3\n",
      "102400/102400 [==============================] - 146s 1ms/step - loss: 0.5363 - accuracy: 0.7322 - categorical_accuracy: 0.7322 - val_loss: 0.5220 - val_accuracy: 0.7434 - val_categorical_accuracy: 0.7434\n",
      "Epoch 3/3\n",
      "102400/102400 [==============================] - 154s 2ms/step - loss: 0.5134 - accuracy: 0.7476 - categorical_accuracy: 0.7476 - val_loss: 0.5166 - val_accuracy: 0.7556 - val_categorical_accuracy: 0.7556\n",
      "32000/32000 [==============================] - 20s 624us/step\n",
      "Test score: 0.5250721302032471\n",
      "Test accuracy: 0.7501562237739563\n"
     ]
    }
   ],
   "source": [
    "# hidden_size = len(word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,EMBEDDING_DIM, weights=[embedding_matrix], trainable=False))\n",
    "model.add(LSTM(128))\n",
    "# model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add((Dense(2)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=3, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102400 samples, validate on 25600 samples\n",
      "Epoch 1/3\n",
      "102400/102400 [==============================] - 167s 2ms/step - loss: 0.6392 - accuracy: 0.6334 - categorical_accuracy: 0.6334 - val_loss: 0.5872 - val_accuracy: 0.6887 - val_categorical_accuracy: 0.6887\n",
      "Epoch 2/3\n",
      "102400/102400 [==============================] - 161s 2ms/step - loss: 0.6061 - accuracy: 0.6712 - categorical_accuracy: 0.6712 - val_loss: 0.5572 - val_accuracy: 0.7202 - val_categorical_accuracy: 0.7202\n",
      "Epoch 3/3\n",
      "102400/102400 [==============================] - 162s 2ms/step - loss: 0.5914 - accuracy: 0.6853 - categorical_accuracy: 0.6853 - val_loss: 0.5474 - val_accuracy: 0.7126 - val_categorical_accuracy: 0.7126\n",
      "32000/32000 [==============================] - 13s 410us/step\n",
      "Test score: 0.552642560005188\n",
      "Test accuracy: 0.7084375023841858\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,EMBEDDING_DIM, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add((Dense(2)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=3, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
